Source:-
http://docs.ansible.com/ansible/intro_inventory.html

Inventory:-

-> Host and Groups
-> Host Variables
-> Group Variables
-> Groups of Groups, and Group Variables
-> Splitting Out Host and Group Specific Data
-> List of Behavioural Inventory Parameters

Ansible works against multiple systems in your infrastructure at the same time. 
It does this by selecting portions of systems listed in Ansible’s inventory file,
which defaults to being saved in the location /etc/ansible/hosts

Not only is this inventory configurable, but you can also use multiple inventory files at the same time(explained below)
and also pull inventory from dynamic or cloud sources, as described in Dynamic Inventory.


[ — Hosts and Groups — ]

The format for /etc/ansible/host is an INI-like format and looks like this:

mail.example.com

[webservers]

client2
client3

[dbservers]

client1
client3

The things in brackets are group names, which are used in classifying systems and deciding what systems you are controlling at what time and for what purpose.

It is ok to place the systems more that one group, for instance a server could be both a webserver and a db server.

If you have hosts that run on non-standard SSH ports you can put the port number after the hostname with a colon. Ports listed in your SSH config file won’t be used with the paramiko connection but will be used with the openssh connection.

To make things explicit, it is suggested that you set them if things are not running on the default port:

host100.example.com:5309


Suppose you have static IPs and want to set up some aliases that live in your host file, or you are connecting through tunnels. 

You can describe hosts like this:

jumper ansible_port=5555 ansible_host=192.168.1.50

In the above example, trying to ansible against the host alias “jumper” (which may not even be a real hostname) will contact 192.168.1.50 on port 5555.
Note that this is using a feature of the inventory file to define some special variables.
Generally speaking this is not the best way to define variables that describe your system policy, but we’ll share suggestions on doing this later. We’re just getting started.


Adding a lot of hosts?
If you have lot of hosts following similar patterns you can do this rather than listing each hostname:

[webservers]
www[01:05].example.com

For numeric patterns, leading zeros can be included or removed, as desired. Ranges are inclusive. You can also define alphabetic ranges:

[databases]

db-[a:f].example.com


You can also select the connection type and user on per host basis:

[targets]


localhost			ansible_connection=local
host100.example.com		ansible_connection=ssh			ansible_user=abhi
host101.example.com		ansible_connection=ssh			ansible_user=auto

As mentioned above, setting these in the inventory file is only a shorthand, and we’ll discuss how to store them in individual files in the ‘host_vars’ directory a bit later on.

	

[ — Host Variables — ]

As alluded to above, it is easy to assign variables to hosts that will be used later in playbooks:

[atlanta]
host1 http_port=80 maxRequestsPerChild=808
host2 http_port=303 maxRequestsPerChild=909



[ — Group Variables — ]

[atlanta]
host1
host2

[atlanta:vars]
ntp_server=ntp.atlanta.example.com
proxy=proxy.atlanta.example.com





[ — Groups of Groups, and Group variables — ]

It is also possible to make groups of groups using the :children suffix. Just like above, you can apply variables using :vars:

[atlanta]
host1
host2

[raleigh]
host2
host3

[southeast:children]
atlanta
raleigh

[southeast:vars]
some_server=foo.southeast.example.com
halon_system_timeout=30
self_destruct_countdown=60
escape_pods=2

[usa:children]
southeast
northeast
southwest
northwest

If you need to store lists or hash data, or prefer to keep host and group specific variables separate from the inventory file, see the next section.





[ — Splitting Out Host and Group Specific Data — ]

The preferred practice in Ansible is actually not to store variable in the main inventory file.

In addition to storing variables directly in the INI file, host and group variables can be stored in individual files relative to the inventory file.


These variable files are in YAML format. Valid file extensions include ‘.yml’, ‘.yaml’, ‘.json’, or no file extensions.








										[ — YAML (Yet another mark up language — ]





[ — YAML Basics — ]

For Ansible, nearly every YAML file starts with a list.
Each item in the list is a list of key/value pairs, commonly called a “hash” or a “dictionary”. So, 
We need to know how to write lists and dictionaries in YAML.


There’s another small irk to YAML.
All YAML file can optionally begin with "---" and end with "..." .This is part of the YAML format and indicates the start and end of a document.


All members of a list are lines beginning at the same indentation level starting with a “ - “ (a dash and a space):

---
# A list of fruits

 fruits:
     - Apple
     - Orange
     - Pineapple
     - Mango


A dictionary is represented in a simple key:value form (the colon must be followed by a space):

# An employee record

- martin:
   name: Martin D’vloper
   job: Developer
   skill: Elite



Dictionaries and lists can also be represented in an abbreviated form if you really want to:

---
employees:
  - martin: {name: Matin D’vloper, job: Developer, skill: Elite}
fruits: [‘Apple’, ‘orange’, ‘Strawberry’, ‘Pineapple’, ‘Mango’]



Ansible doesn’t  really use these too much, but you can also specify a boolean value (true/false) in several forms:


create_keys: yes
needs_agent: no
knows_op: True
likes_emacs: TRUE
uses_cvs: false


Let’s combine what we learned so far in an arbitrary YAML example. This really has nothing to do with Ansible, but will give you a feel for the format:


--- 
# An employee record
name: Martin D’vloper
job: Developer
skill: Elite
employed: True
foods:
   - Apple
   - Orange
   - Strawberry
   - Mango
languages:
   ruby: Elite
   python: Elite
   dotnet: Lame



Gotchas


[ — YAML syntax error: — ]

The following will result in an YAML syntax error.

foo: somebody said I should place a colon here: so I did 

You will want to quote any hash values using colons, like so:

foo: “somebody said I should place a colon here: so I did”



[ — Variables — ]

Unusable uses “{{var}}” for variables.
if a value after a colon starts with a “{“, YAML will think it is a dictionary, so you must quote it, like so:

foo: “{{ variable }}”

The same applies for strings that start or contain any YAML special characters “[] {}:>|”.


Boolean conversion is helpful, but this can be problem when you want a literal yes or other boolean values as a string. In these cases just use quotes:

non_boolean: “yes”
other_string: “false”







Assuming that the inventory file path is 

/etc/ansible/hosts


If the host named ‘foosball’, and in groups ‘raleigh’ and ‘webservers’, variables in YAML files at the following locations will be made available to the host:

/etc/ansible/group_vars/raleigh
/etc/ansible/group_vars/webservers
/etc/ansible/host_vars/foosball


For instance, suppose you have hosts grouped by datacenter, and each datacenter uses some different servers. The data in the groupfile ‘/etc/ansible/group_vars/raleigh’  for the ‘raleigh’ group might look like:

---
ntp_server: acme.example.org
database_serevr: storage.example.org


It is ok if these files do not exist, as this is an optional feature.

As an advanced use-case, you can create directories names after your groups or hosts, and Ansible will read all the files in these directories. An example with ‘raleigh’ group:


/etc/ansible/group_vars/raleigh/db_settings
/etc/ansible/group_vars/raleigh/cluster_settings


All hosts that are in the ‘raleigh’ group will have the variables defined in these files available to them. This can be very useful to keep your variables organised when a single file starts to be too big, or when you want to use Ansible Vault on a part of group’s variables. Note that this only works on Anisble 1.4 or later.


Tip: In Ansible 1.2 or later the group_vars/ and host_vars/ directories can exist in either the playbook directory OR the inventory directory. if both path exists, variable in the playbook directory will override variable set in the inventory directory.

Tip: keeping your inventory file and variables in a git repo (or other version control) is an excellent way to track changes to your inventory and host variables.



[ — List of Behavioural Inventory Parameter — ]

As alluded to above,setting the following variables controls how unusable interacts with remote hosts.


Host connection:

ansible_connection
  Connection type to the host. Candidates are local, smart, ssh or paramiko. The default is smart.




[ — SSH connection — ]


ansible_host
  The name of the host to connect to, if different from the alias you wish to give to it.

ansible_port
  The ssh port number, if not 22

ansible_user
  The default ssh username to use.

ansible_ssh_pass
  The ssh password to use (This is insecure, we strongly recommend using —ask-pass or SSH keys)

ansible_ssh_private_key_file
  Private key file used by ssh. Useful if using multiple keys and you don’t want to use SSH agent.

ansible_ssh_common_args
  This setting is always appended to the default command line for
  sftp, scp and ssh. Useful to configure a ``ProxyCommand`` for a
  certain host (or group)

ansible_sftp_extra_args
  This setting is always appended to the default sftp command line.

ansible_scp_extra_args
  This setting is always appended to the default scp command line.

ansible_ssh_extra_args
  This setting is always appended to the default ssh command line.

ansible_ssh_pipelining
  Determines whether or not to use SSH pipelining. This can override the
  ``pipelining`` setting in ``ansible.cfg``.




[ — Privilege escalation ( see Ansible Privilege Escalation for further details ): — ]

ansible_become
  Equivalent to ansible_sudo or ansible_su, allow to force privilege escalation

ansible_become_method
  Allows to set privilege escalation method

ansible_become_user
  Equivalent to ansible_sudo_user or ansible_su_user, allows to set the user you become through privilege escalation

ansible_become_pass
  Equivalent to ansible_sudo_pass or ansible_su_pass, allows you to set the privilege escalation password



[ — Remote host environment parameters: — ]


ansible_shell_type
  The shell type of the target system. Commands are formatted using ’sh’ -style syntax by default. Setting this ‘csh’ or ‘fish’ will cause commands on target system to follow those shell’s syntax instead.

ansible_python_interpreter
   The target host python path. This is useful for systems with more
  than one Python or not located at "/usr/bin/python" such as \*BSD, or where /usr/bin/python
  is not a 2.X series Python.  We do not use the "/usr/bin/env" mechanism as that requires the remote user's
  path to be set right and also assumes the "python" executable is named python, where the executable might
  be named something like "python26".

ansible\_\*\_interpreter
  Works for anything such as ruby or perl and works just like ansible_python_interpreter.
  This replaces shebang of modules which will run on that host.


Example from a host file

some_host		ansible_port=2222		ansible_user=manager
aws_host		ansible_ssh_private_key_file=/home/example/.ssh/aws.pem
freebsd_host		ansible_python_interpreter=/usr/local/bin/python
ruby_module_host	ansible_ruby_interpreter=/usr/bin/ruby.1.9.3



________________________________________________________________________________________________________________________________________

SRC:- https://serversforhackers.com/an-ansible-tutorial

INSTALLATION:-
sudo apt-add-repository -y ppa:ansible/ansible
sudo apt-get update
sudo apt-get install -y ansible

My host inventory file
vagrant@vagrant-ubuntu-trusty-64:~$ cat /etc/ansible/hosts
[local]
127.0.0.1
[web]
192.168.33.30
192.168.33.40

Basic: Running Commands

Once we have an inventory configured, we can start running Tasks against the defined servers.

Ansible will assume you have SSH access available to your servers, usually based on SSH-Key. Because Ansible uses SSH, the server it's on needs to be able to SSH into the inventory servers. It will attempt to connect as the current user it is being run as. If I'm running Ansible as user vagrant, it will attempt to connect as user vagrant on the other servers.

If Ansible can directly SSH into the managed servers, we can run commands without too much fuss:


Here I have not added the SSH key yet.

vagrant@vagrant-ubuntu-trusty-64:~$ ansible all -m ping 
192.168.33.30 | FAILED => SSH Error: ssh: connect to host 192.168.33.30 port 22: No route to host
    while connecting to 192.168.33.30:22
It is sometimes useful to re-run the command using -vvvv, which prints SSH debug output to help diagnose the issue.
192.168.33.40 | FAILED => SSH Error: ssh: connect to host 192.168.33.40 port 22: No route to host
    while connecting to 192.168.33.40:22
It is sometimes useful to re-run the command using -vvvv, which prints SSH debug output to help diagnose the issue.
127.0.0.1 | FAILED => SSH Error: Permission denied (publickey,password).
    while connecting to 127.0.0.1:22
It is sometimes useful to re-run the command using -vvvv, which prints SSH debug output to help diagnose the issue.
vagrant@vagrant-ubuntu-trusty-64:~$ 



If we need to define the user and perhaps some other settings in order to connect to our server, we can. When testing locally on Vagrant, I use the following:

We can see the output we get from Ansible is some JSON which tells us if the Task made any changes and the result.

vagrant@vagrant-ubuntu-trusty-64:~$ ansible all -m ping -s -k -u vagrant
SSH password: 
127.0.0.1 | success >> {
    "changed": false,
    "ping": "pong"
}

192.168.33.40 | success >> {
    "changed": false,
    "ping": "pong"
}

192.168.33.30 | success >> {
    "changed": false,
    "ping": "pong"
}


Let's cover these commands:

all - Use all defined servers from the inventory file
-m ping - Use the "ping" module, which simply runs the ping command and returns the results
-s - Use "sudo" to run the commands
-k - Ask for a password rather than use key-based authentication
-u vagrant - Log into servers using user vagrant


Modules

Ansible uses "modules" to accomplish most of its Tasks. Modules can do things like install software, copy files, use templates and much more.

Modules are the way to use Ansible, as they can use available context ("Facts") in order to determine what actions, if any need to be done to accomplish a Task.

If we didn't have modules, we'd be left running arbitrary shell commands like this:

vagrant@vagrant-ubuntu-trusty-64:~$ ansible all -s -m shell -a 'apt-get install nginx -y'
127.0.0.1 | success | rc=0 >>
Reading package lists...
Building dependency tree...
Reading state information...
The following extra packages will be installed:
  libxslt1.1 nginx-common nginx-core
Suggested packages:
  fcgiwrap nginx-doc
The following NEW packages will be installed:
  libxslt1.1 nginx nginx-common nginx-core
0 upgraded, 4 newly installed, 0 to remove and 0 not upgraded.
Need to get 493 kB of archives.
After this operation, 1795 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu/ trusty/main libxslt1.1 amd64 1.1.28-2build1 [145 kB]
Get:2 http://archive.ubuntu.com/ubuntu/ trusty-updates/main nginx-common all 1.4.6-1ubuntu3.3 [18.1 kB]
Get:3 http://archive.ubuntu.com/ubuntu/ trusty-updates/main nginx-core amd64 1.4.6-1ubuntu3.3 [324 kB]
Get:4 http://archive.ubuntu.com/ubuntu/ trusty-updates/main nginx all 1.4.6-1ubuntu3.3 [5452 B]
Fetched 493 kB in 8s (57.4 kB/s)
Selecting previously unselected package libxslt1.1:amd64.
(Reading database ... 63636 files and directories currently installed.)
Preparing to unpack .../libxslt1.1_1.1.28-2build1_amd64.deb ...
Unpacking libxslt1.1:amd64 (1.1.28-2build1) ...
Selecting previously unselected package nginx-common.
Preparing to unpack .../nginx-common_1.4.6-1ubuntu3.3_all.deb ...
Unpacking nginx-common (1.4.6-1ubuntu3.3) ...
Selecting previously unselected package nginx-core.
Preparing to unpack .../nginx-core_1.4.6-1ubuntu3.3_amd64.deb ...
Unpacking nginx-core (1.4.6-1ubuntu3.3) ...
Selecting previously unselected package nginx.
Preparing to unpack .../nginx_1.4.6-1ubuntu3.3_all.deb ...
Unpacking nginx (1.4.6-1ubuntu3.3) ...
Processing triggers for ufw (0.34~rc-0ubuntu2) ...
Processing triggers for ureadahead (0.100.0-16) ...
Processing triggers for man-db (2.6.7.1-1ubuntu1) ...
Setting up libxslt1.1:amd64 (1.1.28-2build1) ...
Setting up nginx-common (1.4.6-1ubuntu3.3) ...
Processing triggers for ufw (0.34~rc-0ubuntu2) ...
Processing triggers for ureadahead (0.100.0-16) ...
Setting up nginx-core (1.4.6-1ubuntu3.3) ...
Setting up nginx (1.4.6-1ubuntu3.3) ...
Processing triggers for libc-bin (2.19-0ubuntu6.6) ...

192.168.33.40 | success | rc=0 >>
Reading package lists...
Building dependency tree...
Reading state information...
The following extra packages will be installed:
  libxslt1.1 nginx-common nginx-core
Suggested packages:
  fcgiwrap nginx-doc
The following NEW packages will be installed:
  libxslt1.1 nginx nginx-common nginx-core
0 upgraded, 4 newly installed, 0 to remove and 0 not upgraded.
Need to get 493 kB of archives.
After this operation, 1795 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu/ trusty/main libxslt1.1 amd64 1.1.28-2build1 [145 kB]
Get:2 http://archive.ubuntu.com/ubuntu/ trusty-updates/main nginx-common all 1.4.6-1ubuntu3.3 [18.1 kB]
Get:3 http://archive.ubuntu.com/ubuntu/ trusty-updates/main nginx-core amd64 1.4.6-1ubuntu3.3 [324 kB]
Get:4 http://archive.ubuntu.com/ubuntu/ trusty-updates/main nginx all 1.4.6-1ubuntu3.3 [5452 B]
Fetched 493 kB in 7s (68.1 kB/s)
Selecting previously unselected package libxslt1.1:amd64.
(Reading database ... 62972 files and directories currently installed.)
Preparing to unpack .../libxslt1.1_1.1.28-2build1_amd64.deb ...
Unpacking libxslt1.1:amd64 (1.1.28-2build1) ...
Selecting previously unselected package nginx-common.
Preparing to unpack .../nginx-common_1.4.6-1ubuntu3.3_all.deb ...
Unpacking nginx-common (1.4.6-1ubuntu3.3) ...
Selecting previously unselected package nginx-core.
Preparing to unpack .../nginx-core_1.4.6-1ubuntu3.3_amd64.deb ...
Unpacking nginx-core (1.4.6-1ubuntu3.3) ...
Selecting previously unselected package nginx.
Preparing to unpack .../nginx_1.4.6-1ubuntu3.3_all.deb ...
Unpacking nginx (1.4.6-1ubuntu3.3) ...
Processing triggers for ufw (0.34~rc-0ubuntu2) ...
Processing triggers for ureadahead (0.100.0-16) ...
Processing triggers for man-db (2.6.7.1-1ubuntu1) ...
Setting up libxslt1.1:amd64 (1.1.28-2build1) ...
Setting up nginx-common (1.4.6-1ubuntu3.3) ...
Processing triggers for ufw (0.34~rc-0ubuntu2) ...
Processing triggers for ureadahead (0.100.0-16) ...
Setting up nginx-core (1.4.6-1ubuntu3.3) ...
Setting up nginx (1.4.6-1ubuntu3.3) ...
Processing triggers for libc-bin (2.19-0ubuntu6.6) ...

192.168.33.30 | success | rc=0 >>
Reading package lists...
Building dependency tree...
Reading state information...
The following extra packages will be installed:
  libxslt1.1 nginx-common nginx-core
Suggested packages:
  fcgiwrap nginx-doc
The following NEW packages will be installed:
  libxslt1.1 nginx nginx-common nginx-core
0 upgraded, 4 newly installed, 0 to remove and 0 not upgraded.
Need to get 493 kB of archives.
After this operation, 1795 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu/ trusty/main libxslt1.1 amd64 1.1.28-2build1 [145 kB]
Get:2 http://archive.ubuntu.com/ubuntu/ trusty-updates/main nginx-common all 1.4.6-1ubuntu3.3 [18.1 kB]
Get:3 http://archive.ubuntu.com/ubuntu/ trusty-updates/main nginx-core amd64 1.4.6-1ubuntu3.3 [324 kB]
Get:4 http://archive.ubuntu.com/ubuntu/ trusty-updates/main nginx all 1.4.6-1ubuntu3.3 [5452 B]
Fetched 493 kB in 8s (57.1 kB/s)
Selecting previously unselected package libxslt1.1:amd64.
(Reading database ... 62972 files and directories currently installed.)
Preparing to unpack .../libxslt1.1_1.1.28-2build1_amd64.deb ...
Unpacking libxslt1.1:amd64 (1.1.28-2build1) ...
Selecting previously unselected package nginx-common.
Preparing to unpack .../nginx-common_1.4.6-1ubuntu3.3_all.deb ...
Unpacking nginx-common (1.4.6-1ubuntu3.3) ...
Selecting previously unselected package nginx-core.
Preparing to unpack .../nginx-core_1.4.6-1ubuntu3.3_amd64.deb ...
Unpacking nginx-core (1.4.6-1ubuntu3.3) ...
Selecting previously unselected package nginx.
Preparing to unpack .../nginx_1.4.6-1ubuntu3.3_all.deb ...
Unpacking nginx (1.4.6-1ubuntu3.3) ...
Processing triggers for ufw (0.34~rc-0ubuntu2) ...
Processing triggers for ureadahead (0.100.0-16) ...
Processing triggers for man-db (2.6.7.1-1ubuntu1) ...
Setting up libxslt1.1:amd64 (1.1.28-2build1) ...
Setting up nginx-common (1.4.6-1ubuntu3.3) ...
Processing triggers for ufw (0.34~rc-0ubuntu2) ...
Processing triggers for ureadahead (0.100.0-16) ...
Setting up nginx-core (1.4.6-1ubuntu3.3) ...
Setting up nginx (1.4.6-1ubuntu3.3) ...
Processing triggers for libc-bin (2.19-0ubuntu6.6) ...

vagrant@vagrant-ubuntu-trusty-64:~$ 


Here, the sudo apt-get install nginx command will be run using the "shell" module. The -a flag is used to pass any arguments to the module. I use -s to run this command using sudo.

However this isn't particularly powerful. While it's handy to be able to run these commands on all of our servers at once, we still only accomplish what any bash script might do.

If we used a more appropriate module instead, we can run commands with an assurance of the result. Ansible modules ensure indempotence - we can run the same Tasks over and over without affecting the final result.

For installing software on Debian/Ubuntu servers, the "apt" module will run the same command, but ensure idempotence.



vagrant@vagrant-ubuntu-trusty-64:~$ ansible all -s -m apt -a 'pkg=nginx state=installed update_cache=true'
127.0.0.1 | success >> {
    "changed": false
}

192.168.33.40 | success >> {
    "changed": false
}

192.168.33.30 | success >> {
    "changed": false
}


This will use the apt module to update the repository cache and install Nginx (if not installed).

The result of running the Task was "changed": false. This shows that there were no changes; I had already installed Nginx. I can run this command over and over without worrying about it affecting the desired result.

Going over the command:

all - Run on all defined hosts from the inventory file
-s - Run using sudo
-m apt - Use the apt module
-a 'pkg=nginx state=installed update_cache=true' - Provide the arguments for the apt module, including the package name, our desired end state and whether to update the package repository cache or not
We can run all of our needed Tasks (via modules) in this ad-hoc way, but let's make this more managable. We'll move this Task into a Playbook, which can run and coordinate multiple Tasks.


Basic PlayBook:-

Playbooks can run multiple Tasks and provide some more advanced functionality that we would miss out on using ad-hoc commands. 

Create file nginx.yml:


vagrant@vagrant-ubuntu-trusty-64:~$ cat nginx.yml
---
- hosts: local
  tasks: 
   - name: install nginx
     apt: pkg=nginx state=installed update_cache=true
...
vagrant@vagrant-ubuntu-trusty-64:~$ 


This Task does exactly the same as our ad-hoc command, however I chose to specify my "local" group of servers rather than "all". We can run it with the ansible-playbook command:


vagrant@vagrant-ubuntu-trusty-64:~$ ansible-playbook -s nginx.yml 

PLAY [local] ****************************************************************** 

GATHERING FACTS *************************************************************** 
ok: [127.0.0.1]

TASK: [install nginx] ********************************************************* 
changed: [127.0.0.1]

PLAY RECAP ******************************************************************** 
127.0.0.1                  : ok=2    changed=1    unreachable=0    failed=0   

vagrant@vagrant-ubuntu-trusty-64:~$ 

Use use -s to tell Ansible to use sudo again, and then pass the Playbook file.

We get some useful feedback while this runs, including the Tasks Ansible runs and their result.


Handlers:-

A Handler is exactly the same as a Task (it can do anything a Task can), but it will run when called by another Task. You can think of it as part of an Event system; A Handler will take an action when called by an event it listens for.

This is useful for "secondary" actions that might be required after running a Task, such as starting a new service after installation or reloading a service after a configuration change.


vagrant@vagrant-ubuntu-trusty-64:~$ cat nginx.yml 
---
- hosts: local
  tasks: 
   - name: Install Nginx
     apt: pkg=nginx state=installed update_cache=true
     notify:
      - start nginx
   - name: Ensure Nginx is running
     service: 
      name: nginx
      state: started
  handlers:
    - name: start nginx
      service: name=nginx state=started
...

We can add a notify directive to the installation Task. This notifies any Handler named "Start Nginx" after the Task is run.

Then we can create the Handler called "Start Nginx". This Handler is the Task called when "Start Nginx" is notified.

This particular Handler uses the Service module, which can start, stop, restart, reload (and so on) system services. Here we simply tell Ansible that we want Nginx to be started.

Note that Ansible has us define the state you wish the service to be in, rather than defining the change you want. Ansible will decide if a change is needed, we just tell it the desired result.

vagrant@vagrant-ubuntu-trusty-64:~$ ansible-playbook -s nginx.yml 

PLAY [local] ****************************************************************** 

GATHERING FACTS *************************************************************** 
ok: [127.0.0.1]

TASK: [Install Nginx] ********************************************************* 
ok: [127.0.0.1]

TASK: [Ensure Nginx is running] *********************************************** 
changed: [127.0.0.1]

PLAY RECAP ******************************************************************** 
127.0.0.1                  : ok=3    changed=1    unreachable=0    failed=0   
























 
